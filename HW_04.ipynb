{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 4**\n",
    "\n",
    "Due: **October 22, 5pm** (late submission until October 25th, 5pm -- no submission possible afterwards)\n",
    "\n",
    "Coding assignment: 25 points\n",
    "\n",
    "Project report: 15 points\n",
    "\n",
    "### Name: [Yawen Tan]\n",
    "\n",
    "### Link to the github repo: [https://github.com/IsabellaTan/Brown-DATA2060-HW4#]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the evironment test below, make sure you get all green checks. If not, you will lose 2 points for each red or missing sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.12.11\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.10.5 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 2.3.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 1.7.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 2.3.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pytest version 8.4.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m torch version 2.7.1 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12.11 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.11\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.11\"):\n",
    "    print(FAIL, \"Python version 3.12.11 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'matplotlib': \"3.10.5\", 'numpy': \"2.3.2\",'sklearn': \"1.7.1\", \n",
    "                'pandas': \"2.3.2\", 'pytest': \"8.4.1\", 'torch':\"2.7.1\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Coding Assignment** (25 points)\n",
    "\n",
    "### Introduction\n",
    "In this assignment, you'll implement Binary Logistic Regression with\n",
    "regularization to perform classification. This classification task is to\n",
    "predict whether or not a given patient has breast cancer based on health\n",
    "data. The regularization method that you will be using is Tikhonov\n",
    "regularization (L2 norm). You will also do cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stencil Code & Data\n",
    "\n",
    "We have provided the following stencil code within this file:\n",
    "\n",
    "-   `models` contains the `RegularizedLogisticRegression` model which\n",
    "    you will be implementing.\n",
    "    \n",
    "-   `main` is the entry point of your program which will read in the\n",
    "    data, run the classifier and print the results.\n",
    "\n",
    "-   `Check Model` contains a series of tests to ensure you are coding your \n",
    "    model properly.\n",
    "    \n",
    "You should not modify any code in the `main`. If you do for debugging\n",
    "or other purposes, please make sure any additions are commented out in\n",
    "the final handin. Do not modify or move the `Check Model` cell! If you \n",
    "do so, you will lose points. The unit tests in that cell make it easy \n",
    "to grade your solution. All the functions you need to fill in reside \n",
    "in this notebook, marked by `TODO`s. You can see a full description \n",
    "of them in the section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Breast Cancer Wisconsin (Diagnostic) Data Set \n",
    "\n",
    "You will use a preprocessed version of the Breast Cancer Wisconsin\n",
    "(Diagnostic) Data Set from UC Irvine's Machine Learning Repository site.\n",
    "You can read more about the dataset here at\n",
    "<https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)>.\n",
    "We have split it up into train and validation sets already\n",
    "for you and read them in in `main`.\n",
    "\n",
    "## **The Assignment**\n",
    "\n",
    "We provide you with a sigmoid function to use when training your data.\n",
    "In `models`, there are five functions you will implement. They are:\n",
    "\n",
    "-   `RegularizedLogisticRegression`:\n",
    "\n",
    "    -   **`train()`** uses batch stochastic gradient descent to learn\n",
    "        the weights. You may find your solution from HW03 to be helpful,\n",
    "        but in this assignment, we will train for a finite number of\n",
    "        epochs rather than until we reach a particular convergence\n",
    "        criteria. The weight update step for this assignment will also\n",
    "        be different from HW03.\n",
    "\n",
    "    -   **`predict()`** predicts the labels using the inputs of test\n",
    "        data.\n",
    "\n",
    "    -   **`accuracy()`** computes the percentage of the correctly\n",
    "        predicted labels over a dataset.\n",
    "\n",
    "    -   **`runTrainTestValSplit()`** trains and evaluates for multiple\n",
    "        values of the hyperparameter lambda. This function evaluates\n",
    "        models by using train/validation sets, and\n",
    "        returns lists of training and validation errors with respect to\n",
    "        each value of lambda.\n",
    "\n",
    "    -   **`runKFold()`** evaluates models by implementing k-fold cross\n",
    "        validation, and returns a list of errors with respect to each\n",
    "        value of lambda. Note that we have defined\n",
    "        `_kFoldSplitIndices()` for you, which you may find helpful when\n",
    "        implementing this function.\n",
    "\n",
    "*Note*: You are not allowed to use any off-the-shelf packages that have\n",
    "already implemented these models, such as scikit-learn. We're asking you\n",
    "to implement them yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Binary Logistic Regression**\n",
    "\n",
    "Similar to homework 3, we are again implementing Logistic Regression for\n",
    "classification. However, note that there are a few key differences. For\n",
    "this assignment, we are performing binary classification, which is a\n",
    "special case of multi-class classification. We are also implementing\n",
    "regularization, so you should think about how you would need to modify\n",
    "the loss function and gradient provided below to include regularization.\n",
    "For this problem, there are only two classes, which are denoted by\n",
    "$\\{0, 1\\}$ labels.\\\n",
    "Our model will perform the following:\n",
    "\n",
    "$$h(x) = \\frac{1}{1 + e^{-<w, x>}}$$\n",
    "\n",
    "where $w$ is the model's weights and $h(x)$ is the probability that the\n",
    "data point $x$ has a label of 1. We have implemented this as\n",
    "`sigmoid_function()` for you.\\\n",
    "\\\n",
    "Our loss function will be Binary Log Loss, also called Binary Cross\n",
    "Entropy Loss:\n",
    "\n",
    "$$L_S(h) = -\\frac{1}{m} \\sum_{i=1}^m (y_i \\log h(x_i) + (1 - y_i)\\log (1 - h(x_i)))$$\n",
    "\n",
    "on a sample $S$ of $m$ data points. Therefore, the corresponding\n",
    "gradient of the Binary Log loss with respect to the model's weights is\n",
    "$$\\frac{\\partial L_S(h)}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^m (h(x_i) - y_i)x_{ij}$$\n",
    "\n",
    "### **Regularize with Tikhonov Regularization**\n",
    "\n",
    "As mentioned in the introduction part, with Tikhonov regularization, you\n",
    "just need to implement the L2 norm of the weights, which is\n",
    "$\\lambda||w||_2^2 = \\lambda\\sum_{i=1}^{d}w_i^2$\n",
    "\n",
    "With that added, the gradient used to update the weights has to be adjusted to include\n",
    "$$\\frac{\\partial \\lambda\\sum_{i=1}^{d}w_i^2}{\\partial w_j} = 2\\lambda w_j$$\n",
    "Notice that the $\\lambda$ parameter above is used to control the\n",
    "contribution of the regularization term to the overall learning process\n",
    "that you may have to tune a little bit when implementing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid_function(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "class RegularizedLogisticRegression(object):\n",
    "    '''\n",
    "    Implement regularized logistic regression for binary classification.\n",
    "    The weight vector w should be learned by minimizing the regularized loss\n",
    "    L(h, (x,y)) = log(1 + exp(-y <w, x>)) + lambda |w|_2^2. In other words, the objective\n",
    "    function that we are trying to minimize is the log loss for binary logistic regression \n",
    "    plus Tikhonov regularization with a coefficient of lambda.\n",
    "    '''\n",
    "    def __init__(self, batch_size = 15):\n",
    "        self.learningRate = 0.00001 # Feel free to play around with this if you'd like, though this value will do\n",
    "        self.num_epochs = 10000 # Feel free to play around with this if you'd like, though this value will do\n",
    "        self.batch_size = batch_size # Feel free to play around with this if you'd like, though this value will do\n",
    "        self.weights = None\n",
    "        self.lmbda = 2.5 # tune this parameter\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        '''\n",
    "        Train the model, using batch stochastic gradient descent\n",
    "        @params:\n",
    "            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "            Y: a 1D Numpy array containing the corresponding labels for each example\n",
    "        @return:\n",
    "            None\n",
    "        '''\n",
    "        #[TODO]\n",
    "        \n",
    "        # Convert X and Y to float type\n",
    "        X = np.array(X, dtype=float)\n",
    "        Y = np.array(Y, dtype=float)\n",
    "        # Get number of examples and features\n",
    "        num_examples, num_features = X.shape\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights = np.zeros((1, X.shape[1]))\n",
    "\n",
    "        # Loop over epochs\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Generate a list of indices\n",
    "            indices = list(range(num_examples))\n",
    "            # shuffle the indices\n",
    "            np.random.shuffle(indices)\n",
    "            # Order X and Y according to the shuffled indices\n",
    "            X_shuffled = X[indices]\n",
    "            Y_shuffled = Y[indices]\n",
    "            # Loop over batches\n",
    "            for start in range(0, num_examples, self.batch_size):\n",
    "                end = start + self.batch_size\n",
    "                X_batch = X_shuffled[start:end]\n",
    "                Y_batch = Y_shuffled[start:end]\n",
    "                m_batch = X_batch.shape[0]\n",
    "                # if batch is empty, skip\n",
    "                if m_batch == 0:\n",
    "                    continue\n",
    "                # Calculate z = X * w^T\n",
    "                z = X_batch.dot(self.weights.T).reshape(-1)\n",
    "                # Find the predictions\n",
    "                h = sigmoid_function(z)\n",
    "                # Calculate gradient without regularization (1/m) * X^T * (h - y)\n",
    "                diff = (h - Y_batch)\n",
    "                grad_no_reg = (X_batch.T.dot(diff) / m_batch).reshape(num_features, 1)\n",
    "                # Calculate L2 regularization gradient 2 * lambda * w\n",
    "                grad_reg = 2 * self.lmbda * self.weights.T\n",
    "                # Calculate total gradient\n",
    "                grad_total = grad_no_reg + grad_reg\n",
    "                # Update weights\n",
    "                self.weights = self.weights - self.learningRate * grad_total.T\n",
    "        # Convert weights to array\n",
    "        self.weights = np.array(self.weights, dtype=float)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Compute predictions based on the learned parameters and examples X\n",
    "        @params:\n",
    "            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "        @return:\n",
    "            A 1D Numpy array with one element for each row in X containing the predicted class.\n",
    "        '''\n",
    "        #[TODO]\n",
    "        # Convert X to float type\n",
    "        X = np.array(X, dtype=float)\n",
    "        # Calculate z = X * w^T\n",
    "        z = X.dot(self.weights.T).reshape(-1)\n",
    "        # Calculate predicted probabilities\n",
    "        probs = sigmoid_function(z)\n",
    "        # Covert probabilities to class labels, using threshold 0.5 \n",
    "        # if prob >= 0.5, predict 1, else predict 0\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "        # return predictions\n",
    "        return preds\n",
    "        \n",
    "\n",
    "    def accuracy(self,X, Y):\n",
    "        '''\n",
    "        Output the accuracy of the trained model on a given testing dataset X and labels Y.\n",
    "        @params:\n",
    "            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "            Y: a 1D Numpy array containing the corresponding labels for each example\n",
    "        @return:\n",
    "            a float number indicating accuracy (between 0 and 1)\n",
    "        '''\n",
    "        #[TODO]\n",
    "        # Convert X and Y to float and int types respectively\n",
    "        X = np.array(X, dtype=float)\n",
    "        Y = np.array(Y, dtype=int)\n",
    "        # Predict labels for X\n",
    "        preds = self.predict(X)  # 1D numpy array, 0/1\n",
    "        # Count correct predictions\n",
    "        correct = np.sum(preds == Y)\n",
    "        # Calculate accuracy = number of correct prediction / total number of samples\n",
    "        accuracy = correct / len(Y)\n",
    "        # return accuracy\n",
    "        return accuracy\n",
    "\n",
    "    def runTrainTestValSplit(self, lambda_list, X_train, Y_train, X_val, Y_val):\n",
    "        '''\n",
    "        Given the training and validation data, fit the model with training data and test it with\n",
    "        respect to each lambda. Record the training error and validation error, which are equivalent \n",
    "        to (1 - accuracy).\n",
    "        @params:\n",
    "            lambda_list: a list of lambdas\n",
    "            X_train: a 2D Numpy array for trainig where each row contains an example,\n",
    "            padded by 1 column for the bias\n",
    "            Y_train: a 1D Numpy array for training containing the corresponding labels for each example\n",
    "            X_val: a 2D Numpy array for validation where each row contains an example,\n",
    "            padded by 1 column for the bias\n",
    "            Y_val: a 1D Numpy array for validation containing the corresponding labels for each example\n",
    "        @returns:\n",
    "            train_errors: a list of training errors with respect to the lambda_list\n",
    "            val_errors: a list of validation errors with respect to the lambda_list\n",
    "        '''\n",
    "        train_errors = []\n",
    "        val_errors = []\n",
    "        #[TODO] train model and calculate train and validation errors here for each lambda\n",
    "        # Loop over each lambda\n",
    "        for lmbda in lambda_list:\n",
    "            # Set lambda\n",
    "            self.lmbda = lmbda\n",
    "            # Train the model\n",
    "            self.train(X_train, Y_train)\n",
    "            # Calculate and record training and validation errors\n",
    "            train_errors.append(1 - self.accuracy(X_train, Y_train))\n",
    "            val_errors.append(1 - self.accuracy(X_val, Y_val))\n",
    "        # return results\n",
    "        return train_errors, val_errors\n",
    "\n",
    "\n",
    "    def _kFoldSplitIndices(self, dataset, k):\n",
    "        '''\n",
    "        Helper function for k-fold cross validation. Evenly split the indices of a\n",
    "        dataset into k groups.\n",
    "        For example, indices = [0, 1, 2, 3] with k = 2 may have an output\n",
    "        indices_split = [[1, 3], [2, 0]].\n",
    "        \n",
    "        Please don't change this.\n",
    "        @params:\n",
    "            dataset: a Numpy array where each row contains an example\n",
    "            k: an integer, which is the number of folds\n",
    "        @return:\n",
    "            indices_split: a list containing k groups of indices\n",
    "        '''\n",
    "        num_data = dataset.shape[0]\n",
    "        fold_size = int(num_data / k)\n",
    "        indices = np.arange(num_data)\n",
    "        np.random.shuffle(indices)\n",
    "        indices_split = np.split(indices[:fold_size*k], k)\n",
    "        return indices_split\n",
    "\n",
    "    def runKFold(self, lambda_list, X, Y, k = 3):\n",
    "        '''\n",
    "        Run k-fold cross validation on X and Y with respect to each lambda. Return all k-fold\n",
    "        errors.\n",
    "        \n",
    "        Each run of k-fold involves k iterations. For an arbitrary iteration i, the i-th fold is\n",
    "        used as testing data while the rest k-1 folds are combined as one set of training data. The k results are\n",
    "        averaged as the cross validation error.\n",
    "        @params:\n",
    "            lambda_list: a list of lambdas\n",
    "            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias\n",
    "            Y: a 1D Numpy array containing the corresponding labels for each example\n",
    "            k: an integer, which is the number of folds, k is 3 by default\n",
    "        @return:\n",
    "            k_fold_errors: a list of k-fold errors with respect to the lambda_list\n",
    "        '''\n",
    "        k_fold_errors = []\n",
    "        for lmbda in lambda_list:\n",
    "            self.lmbda = lmbda\n",
    "            #[TODO] call _kFoldSplitIndices to split indices into k groups randomly\n",
    "            fold_indices = self._kFoldSplitIndices(X, k)\n",
    "            fold_errors = []\n",
    "            #[TODO] for each iteration i = 1...k, train the model using lmbda\n",
    "            # on k−1 folds of data. Then test with the i-th fold.\n",
    "            for i in range(k):\n",
    "                # Get the ith fold as validation set\n",
    "                val_idx = fold_indices[i]\n",
    "                # Get validation data\n",
    "                X_val_fold = X[val_idx]\n",
    "                Y_val_fold = Y[val_idx]\n",
    "                # Get training data by combining other folds\n",
    "                train_idx_list = []  # set up an empty list to hold training indices\n",
    "                for j in range(k):\n",
    "                    if j != i: # skip the validation fold\n",
    "                        train_idx_list += list(fold_indices[j])  # add indices from other folds\n",
    "                # Convert to numpy array\n",
    "                train_idx = np.array(train_idx_list)\n",
    "                # Get training data\n",
    "                X_train_fold = X[train_idx]\n",
    "                Y_train_fold = Y[train_idx]\n",
    "                # Train the model on training fold\n",
    "                self.train(X_train_fold, Y_train_fold)\n",
    "                # Calculate and record fold error\n",
    "                fold_error = 1 - self.accuracy(X_val_fold, Y_val_fold) # error = 1 - accuracy\n",
    "                fold_errors.append(fold_error)\n",
    "            #[TODO] calculate and record the cross validation error by averaging total errors\n",
    "            k_fold_errors.append(np.mean(fold_errors))\n",
    "\n",
    "        return k_fold_errors\n",
    "\n",
    "    def plotError(self, lambda_list, train_errors, val_errors, k_fold_errors):\n",
    "        '''\n",
    "        Produce a plot of the cost function on the training and validation sets, and the\n",
    "        cost function of k-fold with respect to the regularization parameter lambda. Use this plot\n",
    "        to determine a valid lambda.\n",
    "        @params:\n",
    "            lambda_list: a list of lambdas\n",
    "            train_errors: a list of training errors with respect to the lambda_list\n",
    "            val_errors: a list of validation errors with respect to the lambda_list\n",
    "            k_fold_errors: a list of k-fold errors with respect to the lambda_list\n",
    "        @return:\n",
    "            None\n",
    "        '''\n",
    "        plt.figure()\n",
    "        plt.semilogx(lambda_list, train_errors, label = 'training error')\n",
    "        plt.semilogx(lambda_list, val_errors, label = 'validation error')\n",
    "        plt.semilogx(lambda_list, k_fold_errors, label = 'k-fold error')\n",
    "        plt.xlabel('lambda')\n",
    "        plt.ylabel('error')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Yawen Tan\n",
      "Date: 2025-10-22\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "# Sets random seed for testing purposes\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Creates Test Models\n",
    "test_model1 = RegularizedLogisticRegression(3)\n",
    "test_model2 = RegularizedLogisticRegression(3)\n",
    "\n",
    "# Creates Test Data\n",
    "x_bias = np.array([[0,4,1], [0,3,1], [5,0,1], [4,1,1], [0,5,1]])\n",
    "y = np.array([0,0,1,1,0])\n",
    "x_bias_test = np.array([[0,0,1], [-5,3,1], [9,0,1], [1,0,1], [6,-7,1]])\n",
    "y_test = np.array([0,0,1,0,1])\n",
    "\n",
    "x_bias2 = np.array([[0,0,1], [0,3,1], [4,0,1], [6,1,1], [0,1,1], [0,4,1]])\n",
    "y2 = np.array([0,1,1,1,0,1])\n",
    "x_bias_test2 = np.array([[0,0,1], [-5,-3,1], [9,0,1], [1,0,1]])\n",
    "y_test2 = np.array([0,0,1,0])\n",
    "\n",
    "\n",
    "# Test Train Model and Checks Model Weights\n",
    "test_model1.train(x_bias, y)\n",
    "weights1 = test_model1.weights\n",
    "assert isinstance(weights1, np.ndarray)\n",
    "assert weights1.ndim==2 and weights1.shape == (1,3)\n",
    "assert weights1 == pytest.approx(np.array([[0.12661045, -0.14658517, -0.01241918]]), 0.05)\n",
    "\n",
    "test_model2.train(x_bias2, y2)\n",
    "weights2 = test_model2.weights\n",
    "assert isinstance(weights2, np.ndarray)\n",
    "assert weights2.ndim==2 and weights2.shape == (1,3)\n",
    "assert weights2 == pytest.approx(np.array([[0.11113, 0.08361, 0.01943]]), 0.05) \n",
    "\n",
    "# Test Model Predict\n",
    "predict1 = test_model1.predict(x_bias_test)\n",
    "assert isinstance(predict1, np.ndarray)\n",
    "assert predict1.ndim==1 and predict1.shape==(5,)\n",
    "assert (predict1 == np.array([0, 0, 1, 1, 1])).all()\n",
    "\n",
    "predict2 = test_model2.predict(x_bias_test2)\n",
    "assert isinstance(predict2, np.ndarray)\n",
    "assert predict2.ndim==1 and predict2.shape==(4,)\n",
    "assert (test_model2.predict(x_bias_test2) == np.array([1, 0, 1, 1])).all()\n",
    "\n",
    "# Test Model Accuracy\n",
    "accuracy1 = test_model1.accuracy(x_bias_test, y_test)\n",
    "assert isinstance(accuracy1, float)\n",
    "assert accuracy1 == .8\n",
    "\n",
    "accuracy2 = test_model2.accuracy(x_bias_test2, y_test2)\n",
    "assert isinstance(accuracy2, float)\n",
    "assert accuracy2 == .5\n",
    "\n",
    "from datetime import date\n",
    "#[TODO] Print your name and the date, using today function from date \n",
    "print('Name: Yawen Tan')\n",
    "print('Date:', date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9340659340659341\n",
      "Validation Accuracy: 0.9649122807017544\n",
      "[1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
      "[np.float64(0.07472527472527468), np.float64(0.07252747252747249), np.float64(0.07252747252747249), np.float64(0.05934065934065935), np.float64(0.03516483516483515), np.float64(0.03516483516483515), np.float64(0.03516483516483515)] [np.float64(0.03508771929824561), np.float64(0.03508771929824561), np.float64(0.03508771929824561), np.float64(0.03508771929824561), np.float64(0.02631578947368418), np.float64(0.02631578947368418), np.float64(0.02631578947368418)] [np.float64(0.0652557319223986), np.float64(0.06701940035273372), np.float64(0.06349206349206353), np.float64(0.0564373897707231), np.float64(0.04409171075837748), np.float64(0.03703703703703709), np.float64(0.04232804232804236)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract():\n",
    "    X_train = pd.read_csv('data/X_train.csv',header=None)\n",
    "    Y_train = pd.read_csv('data/y_train.csv',header=None)\n",
    "    X_val = pd.read_csv('data/X_val.csv',header=None)\n",
    "    Y_val = pd.read_csv('data/y_val.csv',header=None)\n",
    "\n",
    "    Y_train = np.array([i[0] for i in Y_train.values])\n",
    "    Y_val = np.array([i[0] for i in Y_val.values])\n",
    "\n",
    "    X_train = np.append(X_train, np.ones((len(X_train), 1)), axis=1)\n",
    "    X_val = np.append(X_val, np.ones((len(X_val), 1)), axis=1)\n",
    "\n",
    "    return X_train, X_val, Y_train, Y_val\n",
    "\n",
    "def main():\n",
    "    X_train, X_val, Y_train, Y_val = extract()\n",
    "    X_train_val = np.concatenate((X_train, X_val))\n",
    "    Y_train_val = np.concatenate((Y_train, Y_val))\n",
    "\n",
    "    RR = RegularizedLogisticRegression()\n",
    "    RR.train(X_train, Y_train)\n",
    "    print('Train Accuracy: ' + str(RR.accuracy(X_train, Y_train)))\n",
    "    print('Validation Accuracy: ' + str(RR.accuracy(X_val, Y_val)))\n",
    "\n",
    "    #[TODO] Once implemented, uncomment the following lines of code and:\n",
    "    # 1. implement runTrainTestValSplit to get the training and validation errors of our 70-15-15\n",
    "    #    split to the original dataset\n",
    "    # 2. implement runKFold to generate errors of each lambda, where k = 3 in this assignment\n",
    "    # 3. call plotError to plot those errors with respect to lambdas\n",
    "    \n",
    "    lambda_list = [1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
    "    train_errors, val_errors = RR.runTrainTestValSplit(lambda_list, X_train, Y_train, X_val, Y_val)\n",
    "    k_fold_errors = RR.runKFold(lambda_list, X_train_val, Y_train_val, 3)\n",
    "    print(lambda_list)\n",
    "    print(train_errors, val_errors, k_fold_errors)\n",
    "    RR.plotError(lambda_list, train_errors, val_errors, k_fold_errors)\n",
    "    \n",
    "    \n",
    "# Set random seeds. DO NOT CHANGE THIS IN YOUR FINAL SUBMISSION.\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Report** (15 points)\n",
    "\n",
    "### **Question 1**\n",
    "Briefly explain how you used batch stochastic gradient descent with\n",
    "regularization to learn the weights. Think about how the\n",
    "regularization is incorporated into the loss function and how that\n",
    "affects the gradient when updating weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "In the process of batch stochastic gradient descent (SGD) to learn the weights of the logistic regression model, I initialize the weight first. And in each epoch, shuffle the training data and divide it into batches. For each batch, compute the predicted probabilities using the sigmoid function, calculate the gradient of the logistic loss, and add the L2 regularization term 2λw to the gradient. The weights are then updated by subtracting the learning rate times the total gradient.\n",
    "\n",
    "The regularization is incorporated into the loss function as an L2 penalty on the weights. It adds 2λw to the gradient, which discourages large weights and helps prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**\n",
    "\n",
    "Use `plotError()`, which we have implemented for you, to produce a\n",
    "model selection curve. Include your plot here. Then, conclude what\n",
    "the best value of lambda is and explain why. <br>\n",
    "*Note: It takes about 10-15 minutes to generate a graph.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "<<img src=\"graph.png\" width=\"500\">\n",
    "\n",
    "\n",
    "The best λ is 0.01.\n",
    "\n",
    "For the training error (blue), when λ is small (0.001–0.01), the error remains low and nearly flat, showing that the model fits the training data well under weak regularization. As λ increases beyond 0.1, the training error rises sharply, which reflects stronger L2 regularization shrinking model weights and reducing flexibility — leading to underfitting.\n",
    "\n",
    "For the validation error (orange), the minimum occurs near λ = 0.01. When λ < 0.01, there is no further improvement, suggesting that very weak regularization provides little additional benefit. When λ ≥ 0.1, the validation error steadily increases, indicating over-regularization.\n",
    "\n",
    "For the k-fold error (green), the average generalization error across folds decreases toward λ = 0.01 and then increases again, following a similar trend to the validation curve.\n",
    "\n",
    "Thus, λ = 0.01 achieves the best balance between bias and variance — it keeps the training error low while minimizing both validation and k-fold errors, leading to the strongest generalization performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**\n",
    "In this project, you used validation data to select a model. Suppose\n",
    "that each patient might've had multiple samples (e.g., multiple lab\n",
    "tests or x-rays) collected and entered into the dataset. Would you\n",
    "need to account for this when splitting your train-validation-test\n",
    "data? If yes, how? If no, why not? (3-5 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Yes, we need to account for this. If a single patient has multiple samples in the dataset, splitting the data randomly could place some of their samples in the training set and others in the validation or test set. This would lead to data leakage because the model could “see” information about the same patient during training that appears in validation or testing, artificially inflating performance. To prevent this, all samples from the same patient should be grouped together and assigned entirely to either the training, validation, or test set. This ensures that the model is evaluated on entirely unseen patients, providing a more realistic measure of generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
